[net]
batch=512
subdivisions=1
height=19
width=19
channels=1
momentum=0.9
decay=0.0005

burn_in=1000
learning_rate=0.1
policy=poly
power=4
max_batches=10000000

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=256
size=3
stride=1
pad=1
activation=relu
batch_normalize=1

[convolutional]
filters=1
size=1
stride=1
pad=1
activation=linear

[reorg]
extra=1
stride=1

[softmax]

